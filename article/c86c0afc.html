<!DOCTYPE html><html lang="zh-CN"><head><meta charset="utf-8"><meta name="viewport" content="width=device-width,initial-scale=1,maximum-scale=1"><meta name="keywords" content="Hexo Theme Keep"><meta name="description" content="Hexo Theme Keep"><meta name="author" content="涂寐"><title>爬虫之数据解析相关 | 涂寐&#39;s Blogs</title><link rel="stylesheet" href="/css/style.css"><link rel="shortcut icon" href="https://cdn.statically.io/gh/0xtlu/blogsPicture/main/favicon.ico"><link rel="stylesheet" href="//cdn.jsdelivr.net/npm/hexo-theme-keep@3.5.2/source/fontawesome/css/fontawesome.min.css"><link rel="stylesheet" href="//cdn.jsdelivr.net/npm/hexo-theme-keep@3.5.2/source/fontawesome/css/regular.min.css"><link rel="stylesheet" href="//cdn.jsdelivr.net/npm/hexo-theme-keep@3.5.2/source/fontawesome/css/solid.min.css"><link rel="stylesheet" href="//cdn.jsdelivr.net/npm/hexo-theme-keep@3.5.2/source/fontawesome/css/brands.min.css"><script id="hexo-configurations">let KEEP=window.KEEP||{};KEEP.hexo_config={hostname:"example.com",root:"/",language:"zh-CN",path:"search.json"},KEEP.theme_config={toc:{enable:!0,number:!0,expand_all:!1,init_open:!0},style:{primary_color:"#0066cc",logo:"https://cdn.statically.io/gh/0xtlu/blogsPicture/main/favicon.ico",favicon:"https://cdn.statically.io/gh/0xtlu/blogsPicture/main/favicon.ico",avatar:"https://cdn.statically.io/gh/0xtlu/blogsPicture/main/favicon.ico",font_size:"18px",font_family:"STKaiti, STSong, STHeiti",hover:{shadow:!0,scale:!0},first_screen:{enable:!0,header_transparent:!0,background_img:"/images/bg.svg",description:"现在的你不努力||未来的你·该有多狼狈",font_color:null,hitokoto:!1},scroll:{progress_bar:!0,percent:!0}},local_search:{enable:!0,preload:!0},code_copy:{},code_block:{tools:{enable:!0,style:"mac"},highlight_theme:"default"},side_tools:{},pjax:{enable:!0},lazyload:{enable:!0},comment:{enable:!0,use:"valine",valine:{appid:"FrcGiaBdfMQqXAnDFY1gwHbS-gzGzoHsz",appkey:"C0Wy6Sfq0qVag0nm59fc1D12",placeholder:"道友，请留步！请留言~"},gitalk:{github_id:null,github_admins:null,repository:null,client_id:null,client_secret:null},twikoo:{env_id:null,region:null,version:"1.6.7"},waline:{server_url:null,reaction:!1,version:2}},post:{author_label:{enable:!0,auto:!0,custom_label_list:["涂寐"]},word_count:{enable:!0,wordcount:!0,min2read:!0},img_align:"center",copyright_info:!0},version:"3.5.2"},KEEP.language_ago={second:"%s 秒前",minute:"%s 分钟前",hour:"%s 小时前",day:"%s 天前",week:"%s 周前",month:"%s 个月前",year:"%s 年前"},KEEP.language_code_block={copy:"复制代码",copied:"已复制",fold:"折叠代码块",folded:"已折叠"}</script><meta name="generator" content="Hexo 6.3.0"></head><body><div class="progress-bar-container"><span class="scroll-progress-bar"></span> <span class="pjax-progress-bar"></span> <i class="pjax-progress-icon fas fa-circle-notch fa-spin"></i></div><main class="page-container"><div class="page-main-content"><div class="page-main-content-top"><header class="header-wrapper"><div class="header-content"><div class="left"><a class="logo-image" href="/"><img src="https://cdn.statically.io/gh/0xtlu/blogsPicture/main/favicon.ico"> </a><a class="logo-title" href="/">涂寐&#39;s Blogs</a></div><div class="right"><div class="pc"><ul class="menu-list"><li class="menu-item"><a href="/">首页</a></li><li class="menu-item"><a href="/archives">归档</a></li><li class="menu-item"><a href="/tags">标签</a></li><li class="menu-item"><a href="/categories">分类</a></li><li class="menu-item"><a href="/links">友链</a></li><li class="menu-item"><a href="/about">关于</a></li><li class="menu-item search search-popup-trigger"><i class="fas fa-search"></i></li></ul></div><div class="mobile"><div class="icon-item search search-popup-trigger"><i class="fas fa-search"></i></div><div class="icon-item menu-bar"><div class="menu-bar-middle"></div></div></div></div></div><div class="header-drawer"><ul class="drawer-menu-list"><li class="drawer-menu-item flex-center"><a href="/">首页</a></li><li class="drawer-menu-item flex-center"><a href="/archives">归档</a></li><li class="drawer-menu-item flex-center"><a href="/tags">标签</a></li><li class="drawer-menu-item flex-center"><a href="/categories">分类</a></li><li class="drawer-menu-item flex-center"><a href="/links">友链</a></li><li class="drawer-menu-item flex-center"><a href="/about">关于</a></li></ul></div><div class="window-mask"></div><script charset="UTF-8" id="LA_COLLECT" src="//sdk.51.la/js-sdk-pro.min.js"></script><script>LA.init({id:"JiZItHVhLKBShkL0",ck:"JiZItHVhLKBShkL0"})</script></header></div><div class="page-main-content-middle"><div class="main-content"><div class="fade-in-down-animation"><div class="post-page-container"><div class="article-content-container"><div class="article-title"><span class="title-hover-animation">爬虫之数据解析相关</span></div><div class="article-header"><div class="avatar"><img src="https://cdn.statically.io/gh/0xtlu/blogsPicture/main/favicon.ico"></div><div class="info"><div class="author"><span class="name">涂寐</span> <span class="author-label">Lv4</span></div><div class="meta-info"><div class="article-meta-info"><span class="article-date article-meta-item"><i class="fa-regular fa-calendar-plus"></i>&nbsp; <span class="pc">2021-12-28 10:26:20</span> <span class="mobile">2021-12-28 10:26</span> </span><span class="article-update-date article-meta-item"><i class="fas fa-file-pen"></i>&nbsp; <span class="pc">2021-12-28 11:00:18</span> </span><span class="article-categories article-meta-item"><i class="fas fa-folder"></i>&nbsp;<ul><li><a href="/categories/python/">Python</a>&nbsp;</li></ul></span><span class="article-tags article-meta-item"><i class="fas fa-tags"></i>&nbsp;<ul><li><a href="/tags/crawler/">爬虫</a>&nbsp;</li></ul></span><span class="article-pv article-meta-item"><i class="fas fa-eye"></i>&nbsp;<span id="busuanzi_value_page_pv"></span></span></div></div></div></div><div class="article-content keep-markdown-body"><h2 id="声明"><a href="#声明" class="headerlink" title="声明"></a>声明</h2><blockquote><p>本教程仅供学习参考，请勿用在非法途径上，违者后果自负，与笔者无关。 –涂寐</p></blockquote><h2 id="聚焦爬虫"><a href="#聚焦爬虫" class="headerlink" title="聚焦爬虫"></a>聚焦爬虫</h2><ul><li>用于爬取页面中指定的页面内容</li></ul><h2 id="编码流程"><a href="#编码流程" class="headerlink" title="编码流程"></a>编码流程</h2><ol><li>指定url</li><li>发起请求</li><li>数据解析</li><li>持久化存储</li></ol><h2 id="方法分类"><a href="#方法分类" class="headerlink" title="方法分类"></a>方法分类</h2><ol><li>正则表达式</li><li>bs4解析</li><li>xpath解析</li></ol><h2 id="简述使用"><a href="#简述使用" class="headerlink" title="简述使用"></a>简述使用</h2><ol><li>需求内容在标签间或作为标签的属性存储</li><li>标签定位</li><li>从标签间或标签属性值中提取所需</li></ol><h2 id="正则表达式"><a href="#正则表达式" class="headerlink" title="正则表达式"></a>正则表达式</h2><h3 id="网页源代码"><a href="#网页源代码" class="headerlink" title="网页源代码"></a>网页源代码</h3><figure class="highlight html"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">div</span> <span class="attr">class</span>=<span class="string">&quot;thumb&quot;</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">a</span> <span class="attr">href</span>=<span class="string">&quot;/article/124982889&quot;</span> <span class="attr">target</span>=<span class="string">&quot;_blank&quot;</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="name">img</span> <span class="attr">src</span>=<span class="string">&quot;//pic.qiushibaike.com/system/pictures/12498/124982889/medium/B39EVD457VB64VZH.jpg&quot;</span> <span class="attr">alt</span>=<span class="string">&quot;糗事#124982889&quot;</span> <span class="attr">class</span>=<span class="string">&quot;illustration&quot;</span> <span class="attr">width</span>=<span class="string">&quot;100%&quot;</span> <span class="attr">height</span>=<span class="string">&quot;auto&quot;</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;/<span class="name">a</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">div</span>&gt;</span></span><br></pre></td></tr></table></figure><h3 id="取src正则"><a href="#取src正则" class="headerlink" title="取src正则"></a>取src正则</h3><figure class="highlight php"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ex = <span class="string">&#x27;&lt;div class=&quot;thumb&quot;&gt;.*?&lt;img src=&quot;(.*?)&quot; alt.*?&lt;/div&gt;&#x27;</span></span><br></pre></td></tr></table></figure><h3 id="糗事百科糗图"><a href="#糗事百科糗图" class="headerlink" title="糗事百科糗图"></a>糗事百科糗图</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#!/usr//bin/env python3</span></span><br><span class="line"><span class="comment"># -*-coding:utf-8-*-</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 解析第一行</span></span><br><span class="line"><span class="comment"># 防止操作系统用户没有将python装在默认的/usr/bin路径里</span></span><br><span class="line"><span class="comment"># 首先会到env设置里查找python的安装路径，再调用对应路径下的解释器程序完成操作</span></span><br><span class="line"><span class="comment"># 白话理解，调用该程序时自动查找合适的python解析器</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 爬取糗事百科图片</span></span><br><span class="line"><span class="keyword">import</span> os.path</span><br><span class="line"><span class="keyword">import</span> re</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&quot;__main__&quot;</span>:</span><br><span class="line">    <span class="comment"># 创个文件夹存储图片</span></span><br><span class="line">    <span class="comment"># 旧</span></span><br><span class="line">    <span class="comment"># if not os.path.exists(&#x27;./qiutuLibs&#x27;):</span></span><br><span class="line">    <span class="comment"># 新</span></span><br><span class="line">    <span class="keyword">if</span> os.path.exists(<span class="string">&#x27;./qiutuLibs&#x27;</span>) <span class="keyword">is</span> <span class="literal">False</span>:</span><br><span class="line">        os.mkdir(<span class="string">&#x27;./qiutuLibs&#x27;</span>)</span><br><span class="line">    headers = &#123;</span><br><span class="line">        <span class="string">&#x27;User-Agent&#x27;</span>: <span class="string">&#x27;Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/96.0.4664.45 Safari/537.36&#x27;</span></span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment"># 爬取单个图片数据</span></span><br><span class="line">    <span class="comment"># # 复制图片地址，看URL</span></span><br><span class="line">    <span class="comment"># url = &#x27;https://pic.qiushibaike.com/system/pictures/12497/124970827/medium/5L6E0C2Y21U8FG4N.jpg&#x27;</span></span><br><span class="line">    <span class="comment"># # content() 方法是返回图片的二进制形式数据</span></span><br><span class="line">    <span class="comment"># # text（字符串） content（二进制）    json()（对象）</span></span><br><span class="line">    <span class="comment"># img_data = requests.get(url=url, headers=headers).content</span></span><br><span class="line">    <span class="comment">#</span></span><br><span class="line">    <span class="comment"># with open(&#x27;./img.jpg&#x27;, &#x27;wb&#x27;) as fp:</span></span><br><span class="line">    <span class="comment">#     fp.write(img_data)</span></span><br><span class="line">    <span class="comment">#     fp.close()</span></span><br><span class="line">    <span class="comment"># print(&#x27;爬取结束，瞅瞅成功不~&#x27;)</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 使用通用爬虫对url对应的页面进行爬取</span></span><br><span class="line">    <span class="comment"># 单页</span></span><br><span class="line">    <span class="comment"># url = &#x27;https://www.qiushibaike.com/imgrank/&#x27;</span></span><br><span class="line">    <span class="comment"># page_text = requests.get(url=url, headers=headers).text</span></span><br><span class="line">    <span class="comment"># 使用聚焦爬虫解析/提取所有图片</span></span><br><span class="line">    <span class="comment"># ex = &#x27;&lt;div class=&quot;thumb&quot;&gt;.*?&lt;img src=&quot;(.*?)&quot; alt.*?&lt;/div&gt;&#x27;</span></span><br><span class="line">    <span class="comment"># img_src_list = re.findall(ex, page_text, re.S)</span></span><br><span class="line">    <span class="comment"># print(img_src_list)</span></span><br><span class="line">    <span class="comment"># for src in img_src_list:</span></span><br><span class="line">    <span class="comment">#     # 拼全地址</span></span><br><span class="line">    <span class="comment">#     src = &#x27;https:&#x27; + src</span></span><br><span class="line">    <span class="comment">#     # 请求二进制数据</span></span><br><span class="line">    <span class="comment">#     img_data = requests.get(url=src, headers=headers).content</span></span><br><span class="line">    <span class="comment">#     # 生成图片名称</span></span><br><span class="line">    <span class="comment">#     img_name = src.split(&#x27;/&#x27;)[-1]</span></span><br><span class="line">    <span class="comment">#     # 图片存储路劲</span></span><br><span class="line">    <span class="comment">#     imgPath = &#x27;./qiutuLibs/&#x27; + img_name</span></span><br><span class="line">    <span class="comment">#     with open(imgPath, &#x27;wb&#x27;) as fp:</span></span><br><span class="line">    <span class="comment">#         fp.write(img_data)</span></span><br><span class="line">    <span class="comment">#         print(img_name, &quot;下载成功&quot;)</span></span><br><span class="line">    <span class="comment">#         fp.close()</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 多页</span></span><br><span class="line">    url = <span class="string">&#x27;https://www.qiushibaike.com/imgrank/page/%d/&#x27;</span></span><br><span class="line">    <span class="comment"># 可迭代对象：https://www.runoob.com/python3/python3-func-range.html</span></span><br><span class="line">    <span class="keyword">for</span> pageNum <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>, <span class="number">2</span>):</span><br><span class="line">        <span class="comment"># 拼接页码</span></span><br><span class="line">        <span class="comment"># 字符串格式化函数：https://www.runoob.com/python/att-string-format.html</span></span><br><span class="line">        <span class="comment"># 老方法</span></span><br><span class="line">        <span class="comment"># new_url = format(url % pageNum)</span></span><br><span class="line">        <span class="comment"># 新方法</span></span><br><span class="line">        new_url = <span class="string">&#x27;&#123;&#125;&#123;&#125;&#x27;</span>.<span class="built_in">format</span>(url, pageNum)</span><br><span class="line">        <span class="built_in">print</span>(new_url)</span><br><span class="line">        page_text = requests.get(url=new_url, headers=headers).text</span><br><span class="line">        <span class="comment"># https://zhuanlan.zhihu.com/p/139596371</span></span><br><span class="line">        <span class="comment"># 使用正则表达式解析/提取所有图片</span></span><br><span class="line">        <span class="comment"># .* 表示匹配除 \n 外任意字符出现零次或多次</span></span><br><span class="line">        <span class="comment"># ? 跟在 * 或 + 后边时，表示懒惰模式，即非贪婪模式，用以匹配尽可能少的字符</span></span><br><span class="line">        <span class="comment"># a.*?b 匹配最短的，以a开始，以b结束的字符串</span></span><br><span class="line">        <span class="comment"># 在正则里面 &quot;()&quot; 代表分组，即一个括号代表一个分组</span></span><br><span class="line">        <span class="comment"># 正则特点，有括号时只能匹配到括号中的内容，没有括号就正常匹配</span></span><br><span class="line">        <span class="comment"># (.*?) 表示仅匹配到括号中的内容</span></span><br><span class="line">        ex = <span class="string">&#x27;&lt;div class=&quot;thumb&quot;&gt;.*?&lt;img src=&quot;(.*?)&quot; alt.*?&lt;/div&gt;&#x27;</span></span><br><span class="line">        <span class="comment"># def findall(pattern, string, flags=0)</span></span><br><span class="line">        <span class="comment"># 返回string中所有与pattern匹配的全部字符串,返回形式为数组</span></span><br><span class="line">        <span class="comment"># re.S参数：正则表达式会将字符串page_text中内容作为一个整体进行匹配，不会对\n进行中断</span></span><br><span class="line">        img_src_list = re.findall(ex, page_text, re.S)</span><br><span class="line">        <span class="keyword">for</span> src <span class="keyword">in</span> img_src_list:</span><br><span class="line">            <span class="comment"># 拼全地址</span></span><br><span class="line">            src = <span class="string">&#x27;https:&#x27;</span> + src</span><br><span class="line">            <span class="comment"># 请求二进制数据，content中存储字节码</span></span><br><span class="line">            img_data = requests.get(url=src, headers=headers).content</span><br><span class="line">            <span class="comment"># 生成图片名称</span></span><br><span class="line">            <span class="comment"># str.split(str=&quot;&quot;, num=string.count(str))</span></span><br><span class="line">            <span class="comment"># split() 通过第一参数 str 指定分隔符对字符串进行切片，如果第二个参数 num 有指定值，则分割为 num+1 个子字符串。</span></span><br><span class="line">            <span class="comment"># src.split(&#x27;/&#x27;)[-1] 对 src 字符串以‘/ ’分割，取出最后一段赋予img_name</span></span><br><span class="line">            img_name = src.split(<span class="string">&#x27;/&#x27;</span>)[-<span class="number">1</span>]</span><br><span class="line">            <span class="comment"># 图片存储路径</span></span><br><span class="line">            imgPath = <span class="string">&#x27;./qiutuLibs/&#x27;</span> + img_name</span><br><span class="line">            <span class="keyword">with</span> <span class="built_in">open</span>(imgPath, <span class="string">&#x27;wb&#x27;</span>) <span class="keyword">as</span> fp:</span><br><span class="line">                fp.write(img_data)</span><br><span class="line">                <span class="built_in">print</span>(img_name, <span class="string">&quot;下载成功&quot;</span>)</span><br><span class="line">                fp.close()</span><br></pre></td></tr></table></figure><h2 id="BS4解析"><a href="#BS4解析" class="headerlink" title="BS4解析"></a>BS4解析</h2><h3 id="简述原理"><a href="#简述原理" class="headerlink" title="简述原理"></a>简述原理</h3><ol><li>实例化一个BeautifulSoup对象，将页面源码数据加载到该对象中</li><li>调用BeautifulSoup对象中的属性和方法进行标签定位和数据提取</li></ol><h3 id="环境安装"><a href="#环境安装" class="headerlink" title="环境安装"></a>环境安装</h3><figure class="highlight php"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Beautiful Soup将复杂HTML文档转换成一个复杂的树形结构，每个节点都是Python对象，所有对象可以归纳为4种：tag，NavigableString，BeautifulSoup，Comment。</span></span><br><span class="line">php install bs4</span><br><span class="line"><span class="comment"># lxml是python的一个解析库，支持HTML和XML的解析，支持XPath解析方式</span></span><br><span class="line">pip install lxml</span><br></pre></td></tr></table></figure><h3 id="使用概要"><a href="#使用概要" class="headerlink" title="使用概要"></a>使用概要</h3><ol><li><p>from bs4 import BeautifulSoup</p></li><li><p>Beautiful Soup对象实例化</p></li><li><p>将本地html文档数据加载到BeautifulSoup对象</p><figure class="highlight php"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">fp = <span class="title function_ invoke__">open</span>(<span class="string">&#x27;./localWeb.html&#x27;</span>, <span class="string">&#x27;r&#x27;</span>, encoding=<span class="string">&#x27;utf-8&#x27;</span>)</span><br><span class="line">soup = <span class="title function_ invoke__">BeautifulSoup</span>(fp, <span class="string">&#x27;lxml&#x27;</span>)</span><br></pre></td></tr></table></figure></li><li><p>或，将门户网站拉取的页面源码加载到BeautifulSoup对象</p></li></ol><figure class="highlight php"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">page_text = response.text</span><br><span class="line">soup = <span class="title function_ invoke__">BeautifulSoup</span>(page_text, <span class="string">&#x27;lxml&#x27;</span>)</span><br></pre></td></tr></table></figure><h3 id="相关属性和方法"><a href="#相关属性和方法" class="headerlink" title="相关属性和方法"></a>相关属性和方法</h3><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"># 本次测试HTML为笔者博客首页网页源码 </span><br><span class="line"></span><br><span class="line">soup.tagName:	返回文档中第一次出现的 tagName 标签</span><br><span class="line">soup.tagName[<span class="string">&#x27;PropertyName&#x27;</span>]：提取 tagName 标签中属性名为 PropertyName 的值</span><br><span class="line">soup.find(<span class="string">&#x27;tagName&#x27;</span>)：返回文档中第一次出现的 tagName 标签</span><br><span class="line">soup.find(<span class="string">&#x27;a&#x27;</span>, class_<span class="operator">=</span>&quot;active&quot;)：根据属性再次定位</span><br><span class="line">soup.find_all(<span class="string">&#x27;tageName&#x27;</span>)：返回所有 tageName 标签的列表</span><br><span class="line">soup.select(<span class="string">&#x27;.selectorName&#x27;</span>)：根据 id<span class="operator">/</span>class 等选择器返回对应列表</span><br><span class="line">soup.select(<span class="string">&#x27;.header-drawer &gt; ul &gt; li &gt;a&#x27;</span>)：层级选择器，一个 <span class="operator">&gt;</span> 表示一个层级</span><br><span class="line">soup.select(<span class="string">&#x27;.header-drawer &gt; ul a&#x27;</span>)：一个 空格 表示多个层级</span><br><span class="line">soup.select(<span class="string">&#x27;.header-drawer &gt; ul a&#x27;</span>)[<span class="number">2</span>]：如数组，通过下标选择列表中的某个，此处选择位序为 <span class="number">3</span> 的 a 标签</span><br><span class="line">soup.select(<span class="string">&#x27;.header-drawer &gt; ul a&#x27;</span>)[<span class="number">1</span>].text：text 属性拿到标签间所有文本内容</span><br><span class="line">soup.select(<span class="string">&#x27;.header-drawer &gt; ul a&#x27;</span>)[<span class="number">3</span>].string：string属性拿到标签间直系文本内容，请通过 find() 方法测试</span><br><span class="line">soup.select(<span class="string">&#x27;.header-drawer &gt; ul a&#x27;</span>)[<span class="number">4</span>].get_text()：get_text() 方法拿到标签间所有文本内容</span><br></pre></td></tr></table></figure><h3 id="本地测试"><a href="#本地测试" class="headerlink" title="本地测试"></a>本地测试</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#!/usr/bin/env python3</span></span><br><span class="line"><span class="comment"># -*-coding:utf-8-*-</span></span><br><span class="line"><span class="keyword">from</span> bs4 <span class="keyword">import</span> BeautifulSoup</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&quot;__main__&quot;</span>:</span><br><span class="line">    <span class="comment"># 加载本地的html文档数据到 BeautifulSoup 对象中</span></span><br><span class="line">    <span class="comment"># 以只读方式、utf-8 编码格式打开 localWeb.html</span></span><br><span class="line">    fp = <span class="built_in">open</span>(<span class="string">&#x27;./localWeb.html&#x27;</span>, <span class="string">&#x27;r&#x27;</span>, encoding=<span class="string">&#x27;utf-8&#x27;</span>)</span><br><span class="line">    <span class="comment"># 调用 BeauSoup 类的构造方法初始化本对象，以 lxml 的解析方式传入 fp 的数据</span></span><br><span class="line">    soup = BeautifulSoup(fp, <span class="string">&#x27;lxml&#x27;</span>)</span><br><span class="line">    <span class="comment"># print(soup)</span></span><br><span class="line">    <span class="comment"># 获取第一次出现的 a 标签</span></span><br><span class="line">    <span class="comment"># print(soup.a)</span></span><br><span class="line">    <span class="comment"># print(soup.div)</span></span><br><span class="line">    <span class="comment"># print(soup.find(&#x27;a&#x27;, class_=&quot;active&quot;))</span></span><br><span class="line">    <span class="comment"># print(soup.find_all(&#x27;a&#x27;))</span></span><br><span class="line">    <span class="comment"># print(soup.select(&#x27;.theme-version&#x27;))</span></span><br><span class="line">    <span class="comment"># 层级选择器，获取标签机间文本内容</span></span><br><span class="line">    <span class="comment"># print(soup.select(&#x27;.header-drawer &gt; ul a&#x27;)[1].text)</span></span><br><span class="line">    <span class="comment"># print(soup.select(&#x27;.header-drawer &gt; ul a&#x27;)[1].string)</span></span><br><span class="line">    <span class="comment"># print(soup.select(&#x27;.header-drawer &gt; ul a&#x27;)[4].get_text())</span></span><br><span class="line">    <span class="comment"># 获取标签属性内容</span></span><br><span class="line">    <span class="built_in">print</span>(soup.a[<span class="string">&#x27;href&#x27;</span>])</span><br></pre></td></tr></table></figure><h3 id="三国演义小说"><a href="#三国演义小说" class="headerlink" title="三国演义小说"></a>三国演义小说</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#!/usr/bin/env python3</span></span><br><span class="line"><span class="comment"># -*-coding:utf-8-*-</span></span><br><span class="line"><span class="comment"># 要求爬取三国演义所有章节标题和内容</span></span><br><span class="line"><span class="comment"># https://www.shicimingju.com/book/sanguoyanyi.html</span></span><br><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"><span class="keyword">from</span> bs4 <span class="keyword">import</span> BeautifulSoup</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&quot;__main__&quot;</span>:</span><br><span class="line">    headers = &#123;</span><br><span class="line">        <span class="string">&#x27;User-Agent&#x27;</span>: <span class="string">&#x27;Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/96.0.4664.93 Safari/537.36&#x27;</span></span><br><span class="line">    &#125;</span><br><span class="line">    url = <span class="string">&#x27;https://www.shicimingju.com/book/sanguoyanyi.html&#x27;</span></span><br><span class="line">    <span class="comment"># 调用 encode(&#x27;ISO-8859-1&#x27;) 方法，解决乱码问题</span></span><br><span class="line">    <span class="comment"># 对返回包进行ISO-8859-1编码，保证了中文的正确读写</span></span><br><span class="line">    page_text = requests.get(url=url, headers=headers).text.encode(<span class="string">&#x27;ISO-8859-1&#x27;</span>)</span><br><span class="line">    <span class="built_in">print</span>(page_text)</span><br><span class="line">    <span class="comment"># 检测编码方式</span></span><br><span class="line">    <span class="comment"># print(page_text.encoding)</span></span><br><span class="line">    <span class="comment"># 在解析章节标题和详情页URL</span></span><br><span class="line">    <span class="comment"># 1、实例化 BeautSoup对象</span></span><br><span class="line">    soup = BeautifulSoup(page_text, <span class="string">&#x27;lxml&#x27;</span>)</span><br><span class="line">    <span class="comment"># 匹配</span></span><br><span class="line">    li_list = soup.select(<span class="string">&#x27;.book-mulu &gt; ul &gt; li&#x27;</span>)</span><br><span class="line">    fp = <span class="built_in">open</span>(<span class="string">&#x27;./sanguo.txt&#x27;</span>, <span class="string">&#x27;w&#x27;</span>, encoding=<span class="string">&#x27;utf-8&#x27;</span>)</span><br><span class="line">    <span class="keyword">for</span> li <span class="keyword">in</span> li_list:</span><br><span class="line">        <span class="comment"># 拿标题</span></span><br><span class="line">        title = li.a.string</span><br><span class="line">        <span class="comment"># 拿URL</span></span><br><span class="line">        detail_url = <span class="string">&#x27;https://www.shicimingju.com&#x27;</span> + li.a[<span class="string">&#x27;href&#x27;</span>]</span><br><span class="line">        <span class="comment"># 请求详情页内容</span></span><br><span class="line">        detail_page_text = requests.get(url=detail_url, headers=headers, ).text.encode(<span class="string">&#x27;ISO-8859-1&#x27;</span>).decode(<span class="string">&#x27;utf-8&#x27;</span>)</span><br><span class="line">        <span class="comment"># print(detail_page_text)</span></span><br><span class="line">        <span class="comment"># 解析详情页内容</span></span><br><span class="line">        detail_soup = BeautifulSoup(detail_page_text, <span class="string">&#x27;lxml&#x27;</span>)</span><br><span class="line">        <span class="comment"># 通过类选择其专门定位该div标签</span></span><br><span class="line">        div_tag = detail_soup.find(<span class="string">&#x27;div&#x27;</span>, class_=<span class="string">&#x27;chapter_content&#x27;</span>)</span><br><span class="line">        <span class="comment"># 得到章节具体内容</span></span><br><span class="line">        <span class="comment"># 看了下，额，红楼梦？这网站运维，阔以</span></span><br><span class="line">        <span class="comment"># 通过text属性或get_text()，获取div标签中的所有文本内容</span></span><br><span class="line">        content = div_tag.get_text()</span><br><span class="line">        fp.write(title + <span class="string">&#x27;:&#x27;</span> + content + <span class="string">&#x27;\n&#x27;</span>)</span><br><span class="line">        <span class="built_in">print</span>(title, <span class="string">&#x27;爬取成功！！！&#x27;</span>)</span><br></pre></td></tr></table></figure><h2 id="xpath解析"><a href="#xpath解析" class="headerlink" title="xpath解析"></a>xpath解析</h2><h3 id="原理"><a href="#原理" class="headerlink" title="原理"></a>原理</h3><ol><li>实例化etree对象，将待解析页面源码加载到其中</li><li>调用etree对象得xpath方法，结合xpath表达式实现标签定位和内容捕获</li></ol><h3 id="环境"><a href="#环境" class="headerlink" title="环境"></a>环境</h3><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip install lxml</span><br></pre></td></tr></table></figure><h3 id="使用举例"><a href="#使用举例" class="headerlink" title="使用举例"></a>使用举例</h3><ol><li>本地：etree.parse(filePath)</li><li>网络：etree.HTML(‘page_text’)</li></ol><h3 id="xpath表达式"><a href="#xpath表达式" class="headerlink" title="xpath表达式"></a>xpath表达式</h3><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="operator">/</span>：表示一个层级，从html标签（根标签）开始定位</span><br><span class="line"><span class="operator">/</span><span class="operator">/</span>：表示多个层级，可从任意位置开始定位</span><br><span class="line">tagName[<span class="variable">@class</span><span class="operator">=</span>&quot;PropertyName&quot;]：属性定位，精准定位</span><br><span class="line">tagName[<span class="variable">@class</span><span class="operator">=</span>&quot;PropertyName&quot;]<span class="operator">/</span>tageName[<span class="number">1</span>]：索引定位，索引以<span class="number">1</span>为始</span><br><span class="line">tagName[<span class="variable">@class</span><span class="operator">=</span>&quot;PropertyName&quot;]<span class="operator">/</span>tageName<span class="operator">/</span>text()：<span class="operator">/</span>text()方法取直系标签文本内容，<span class="operator">/</span><span class="operator">/</span>text()取非直系标签（其下所有）文本内容，返回列表，可通过下标选择某个列表值</span><br><span class="line">tagName[<span class="variable">@class</span><span class="operator">=</span>&quot;PropertyName&quot;]<span class="operator">/</span>tagName<span class="operator">/</span><span class="variable">@PropertyName</span>：通过@标签中属性来提取属性值</span><br></pre></td></tr></table></figure><h3 id="本地测试-1"><a href="#本地测试-1" class="headerlink" title="本地测试"></a>本地测试</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#!/usr/bin/env python3</span></span><br><span class="line"><span class="comment"># -*-coding:utf-8-*-</span></span><br><span class="line"><span class="keyword">from</span> lxml <span class="keyword">import</span> etree</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&quot;__main__&quot;</span>:</span><br><span class="line">    <span class="comment"># 实例化etree对象，并写入本地html源码</span></span><br><span class="line">    <span class="comment"># 默认是XML解析器，碰到不规范的html文件时就会解析错误，增加解析器</span></span><br><span class="line">    parser = etree.HTMLParser(encoding=<span class="string">&#x27;utf-8&#x27;</span>)</span><br><span class="line">    tree = etree.parse(<span class="string">&#x27;localWeb.html&#x27;</span>, parser=parser)</span><br><span class="line">    <span class="comment"># 找网站标题，单一，不会重复</span></span><br><span class="line">    <span class="comment"># r = tree.xpath(&#x27;/html/head/title&#x27;)</span></span><br><span class="line">    <span class="comment"># 匹配到该层级下同辈份的所有div标签，</span></span><br><span class="line">    <span class="comment"># r = tree.xpath(&#x27;/html/body/main/div/div&#x27;)</span></span><br><span class="line">    <span class="comment"># 匹配到使用多层级选择符（//）父级（此处为main）之后不同辈分的所有div标签</span></span><br><span class="line">    <span class="comment"># r = tree.xpath(&#x27;/html/body/main//div&#x27;)</span></span><br><span class="line">    <span class="comment"># 属性定位，精准定位--此处定位到个人名言处</span></span><br><span class="line">    <span class="comment"># r = tree.xpath(&#x27;/html/body/main//div[@class=&quot;description&quot;]&#x27;)</span></span><br><span class="line">    <span class="comment"># 同效果</span></span><br><span class="line">    <span class="comment"># r = tree.xpath(&#x27;//div[@class=&quot;description&quot;]&#x27;)</span></span><br><span class="line">    <span class="comment"># 索引定位</span></span><br><span class="line">    r = tree.xpath(<span class="string">&#x27;//div[@class=&quot;s-icon-list&quot;]/span[1]&#x27;</span>)</span><br><span class="line">    <span class="comment"># /text()方法取直系标签内容，返回列表</span></span><br><span class="line">    <span class="comment"># r = tree.xpath(&#x27;//div[@class=&quot;header-drawer&quot;]//li[2]/a/text()&#x27;)</span></span><br><span class="line">    <span class="comment"># 利用下标选择返回列表的某个值</span></span><br><span class="line">    <span class="comment"># r = tree.xpath(&#x27;//div[@class=&quot;header-drawer&quot;]//li[2]/a/text()&#x27;)[0]</span></span><br><span class="line">    <span class="comment"># //text()取其下所有标签内容</span></span><br><span class="line">    r = tree.xpath(<span class="string">&#x27;//div[@class=&quot;header-drawer&quot;]//li//text()&#x27;</span>)</span><br><span class="line">    <span class="built_in">print</span>(r)</span><br></pre></td></tr></table></figure><h3 id="58二手房"><a href="#58二手房" class="headerlink" title="58二手房"></a>58二手房</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#!/usr/bin/env python3</span></span><br><span class="line"><span class="comment"># -*-coding:utf-8 -*-</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"><span class="keyword">from</span> lxml <span class="keyword">import</span> etree</span><br><span class="line"></span><br><span class="line"><span class="comment"># 爬取58二手房房源信息</span></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&quot;__main__&quot;</span>:</span><br><span class="line">    headers = &#123;</span><br><span class="line">        <span class="string">&#x27;User-Agent&#x27;</span>: <span class="string">&#x27;Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/96.0.4664.93 Safari/537.36 Edg/96.0.1054.53&#x27;</span></span><br><span class="line">    &#125;</span><br><span class="line">    url = <span class="string">&#x27;https://bj.58.com/ershoufang/&#x27;</span></span><br><span class="line">    page_text = requests.get(url=url, headers=headers).text</span><br><span class="line">    <span class="comment"># xpath解析,并定位需求标签（所取内容父标签）</span></span><br><span class="line">    tree = etree.HTML(page_text)</span><br><span class="line">    div_list = tree.xpath(<span class="string">&#x27;//section[@class=&quot;list&quot;]/div&#x27;</span>)</span><br><span class="line">    <span class="comment"># print(div_list)</span></span><br><span class="line">    <span class="comment"># 存储</span></span><br><span class="line">    fp = <span class="built_in">open</span>(<span class="string">&#x27;./58.txt&#x27;</span>, <span class="string">&#x27;w&#x27;</span>, encoding=<span class="string">&#x27;utf-8&#x27;</span>)</span><br><span class="line">    <span class="comment"># 取a标签-div-h3标签的内容</span></span><br><span class="line">    <span class="keyword">for</span> div <span class="keyword">in</span> div_list:</span><br><span class="line">        <span class="comment"># 局部定位</span></span><br><span class="line">        title = div.xpath(<span class="string">&#x27;./a/div[2]//h3/text()&#x27;</span>)[<span class="number">0</span>]</span><br><span class="line">        <span class="comment"># fp.write(title,&#x27;\n&#x27;)相当于用了两次write()，推荐用+连接</span></span><br><span class="line">        fp.write(title + <span class="string">&#x27;\n&#x27;</span>)</span><br><span class="line">        <span class="comment"># fp.close()</span></span><br><span class="line">        <span class="comment"># print(title)</span></span><br></pre></td></tr></table></figure><h3 id="彼岸图网图片"><a href="#彼岸图网图片" class="headerlink" title="彼岸图网图片"></a>彼岸图网图片</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#!/usr/bin/env python3</span></span><br><span class="line"><span class="comment"># -*-coding:utf-8-*-</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 爬取彼岸图网4k图片：https://pic.netbian.com</span></span><br><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"><span class="keyword">from</span> lxml <span class="keyword">import</span> etree</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&quot;__main__&quot;</span>:</span><br><span class="line">    <span class="keyword">if</span> os.path.exists(<span class="string">&#x27;./biantuwang&#x27;</span>) <span class="keyword">is</span> <span class="literal">False</span>:</span><br><span class="line">        os.mkdir(<span class="string">&#x27;./biantuwang&#x27;</span>)</span><br><span class="line">    headers = &#123;</span><br><span class="line">        <span class="string">&#x27;User-Agent&#x27;</span>: <span class="string">&#x27;Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/96.0.4664.93 Safari/537.36 Edg/96.0.1054.53&#x27;</span></span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment"># 其他页面图片URL，可做循环来调用：https://pic.netbian.com/4kdongman/index_2.html</span></span><br><span class="line">    url = <span class="string">&#x27;https://pic.netbian.com/4kdongman/&#x27;</span></span><br><span class="line">    <span class="comment"># page_text = requests.get(url=url, headers=headers).text.encode(&quot;ISO-8859-1&quot;)</span></span><br><span class="line">    response = requests.get(url=url, headers=headers)</span><br><span class="line">    <span class="comment"># 手动设置响应数据的编码方式</span></span><br><span class="line">    <span class="comment"># response.encoding = &#x27;utf-8&#x27;</span></span><br><span class="line">    page_text = response.text</span><br><span class="line">    tree = etree.HTML(page_text)</span><br><span class="line">    <span class="comment"># 建议相对路径的第一个标签属性名为唯一值</span></span><br><span class="line">    li_list = tree.xpath(<span class="string">&#x27;//div[@class=&quot;slist&quot;]/ul/li&#x27;</span>)</span><br><span class="line">    <span class="comment"># print(li_list)</span></span><br><span class="line">    <span class="keyword">for</span> li <span class="keyword">in</span> li_list:</span><br><span class="line">        img_src = <span class="string">&#x27;https://pic.netbian.com&#x27;</span> + li.xpath(<span class="string">&#x27;./a/img/@src&#x27;</span>)[<span class="number">0</span>]</span><br><span class="line">        <span class="comment"># img_src = li.xpath(&#x27;./a/img/@src&#x27;)</span></span><br><span class="line">        img_name = li.xpath(<span class="string">&#x27;./a/img/@alt&#x27;</span>)[<span class="number">0</span>] + <span class="string">&#x27;.jpg&#x27;</span></span><br><span class="line">        <span class="comment"># 通用解决中文乱码，需重新赋值</span></span><br><span class="line">        img_name = img_name.encode(<span class="string">&#x27;ISO-8859-1&#x27;</span>).decode(<span class="string">&#x27;gbk&#x27;</span>)</span><br><span class="line">        <span class="comment"># print(img_name, img_src)</span></span><br><span class="line">        img_data = requests.get(url=img_src, headers=headers).content</span><br><span class="line">        <span class="comment"># 文件夹bianantuwang需提前建立</span></span><br><span class="line">        img_path = <span class="string">&#x27;./biantuwang/&#x27;</span> + img_name</span><br><span class="line">        <span class="comment"># print(img_path)</span></span><br><span class="line">        <span class="keyword">with</span> <span class="built_in">open</span>(img_path, <span class="string">&#x27;wb&#x27;</span>) <span class="keyword">as</span> fp:</span><br><span class="line">            fp.write(img_data)</span><br><span class="line">            fp.close()</span><br><span class="line">            <span class="built_in">print</span>(img_name + <span class="string">&#x27;下载成功！！！&#x27;</span>)</span><br></pre></td></tr></table></figure><h3 id="空气检测平台城市"><a href="#空气检测平台城市" class="headerlink" title="空气检测平台城市"></a>空气检测平台城市</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#!/usr/bin/env python3</span></span><br><span class="line"><span class="comment"># -*-coding:utf-8-*-</span></span><br><span class="line"><span class="comment"># 爬取中国空气质量在线监测分析平台各城市名称</span></span><br><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"><span class="keyword">from</span> lxml <span class="keyword">import</span> etree</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&quot;__main__&quot;</span>:</span><br><span class="line">    headers = &#123;</span><br><span class="line">        <span class="string">&#x27;User-Agent&#x27;</span>: <span class="string">&#x27;Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/96.0.4664.93 Safari/537.36 Edg/96.0.1054.53&#x27;</span></span><br><span class="line">    &#125;</span><br><span class="line">    url = <span class="string">&#x27;https://www.aqistudy.cn/historydata/&#x27;</span></span><br><span class="line">    page_text = requests.get(url=url, headers=headers).text</span><br><span class="line">    <span class="comment"># print(page_text)</span></span><br><span class="line">    tree = etree.HTML(page_text)</span><br><span class="line">    <span class="comment"># print(tree)</span></span><br><span class="line">    <span class="comment"># 懒得分两步了，直接热门和所有一起拉取</span></span><br><span class="line">    li_list = tree.xpath(<span class="string">&#x27;//div[@class=&quot;bottom&quot;]/ul//li&#x27;</span>)</span><br><span class="line">    <span class="comment"># print(li_list)</span></span><br><span class="line">    all_city_names = []</span><br><span class="line">    fp = <span class="built_in">open</span>(<span class="string">&#x27;./citys.txt&#x27;</span>, <span class="string">&#x27;w&#x27;</span>, encoding=<span class="string">&#x27;utf-8&#x27;</span>)</span><br><span class="line">    <span class="keyword">for</span> li <span class="keyword">in</span> li_list:</span><br><span class="line">        city_name = li.xpath(<span class="string">&#x27;./a/text()&#x27;</span>)[<span class="number">0</span>]</span><br><span class="line">        fp.write(city_name + <span class="string">&#x27;\n&#x27;</span>)</span><br><span class="line">        all_city_names.append(city_name)</span><br><span class="line">        <span class="built_in">print</span>(city_name)</span><br><span class="line">    fp.close()</span><br></pre></td></tr></table></figure><h3 id="站长之家免费简历"><a href="#站长之家免费简历" class="headerlink" title="站长之家免费简历"></a>站长之家免费简历</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#!/usr/bin/env python3</span></span><br><span class="line"><span class="comment"># -*-coding:utf-8-*-</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 爬取站长之家免费简历模板</span></span><br><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">from</span> lxml <span class="keyword">import</span> etree</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&quot;__main__&quot;</span>:</span><br><span class="line">    <span class="keyword">if</span> os.path.exists(<span class="string">&#x27;./jianli&#x27;</span>) <span class="keyword">is</span> <span class="literal">False</span>:</span><br><span class="line">        os.mkdir(<span class="string">&#x27;./jianli&#x27;</span>)</span><br><span class="line">    headers = &#123;</span><br><span class="line">        <span class="string">&#x27;User-Agent&#x27;</span>: <span class="string">&#x27;Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/96.0.4664.93 Safari/537.36 Edg/96.0.1054.53&#x27;</span></span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment"># 其他 https://sc.chinaz.com/jianli/free_2.html</span></span><br><span class="line">    url = <span class="string">&#x27;https://sc.chinaz.com/jianli/free_&#123;num&#125;.html&#x27;</span></span><br><span class="line">    <span class="comment"># 多页拉取</span></span><br><span class="line">    <span class="keyword">for</span> x <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">29</span>, <span class="number">30</span>):</span><br><span class="line">        <span class="comment"># new_url = format(url % x)</span></span><br><span class="line">        <span class="comment"># new_url = &#x27;https://sc.chinaz.com/jianli/free_&#123;num&#125;.html&#x27;.format(num=x)</span></span><br><span class="line">        url = url.<span class="built_in">format</span>(num=x)</span><br><span class="line">        <span class="comment"># print(new_url)</span></span><br><span class="line">        <span class="comment"># 单页拉取</span></span><br><span class="line">        <span class="comment"># url = &#x27;https://sc.chinaz.com/jianli/free.html&#x27;</span></span><br><span class="line">        page_text = requests.get(url=url, headers=headers).text</span><br><span class="line">        tree = etree.HTML(page_text)</span><br><span class="line">        <span class="comment"># print(tree)</span></span><br><span class="line">        div_list = tree.xpath(<span class="string">&#x27;//div[@id=&quot;main&quot;]/div/div&#x27;</span>)</span><br><span class="line">        <span class="comment"># print(div_list)</span></span><br><span class="line">        <span class="keyword">for</span> div <span class="keyword">in</span> div_list:</span><br><span class="line">            a_href = <span class="string">&#x27;https:&#x27;</span> + div.xpath(<span class="string">&#x27;./a/@href&#x27;</span>)[<span class="number">0</span>]</span><br><span class="line">            <span class="comment"># print(a_href)</span></span><br><span class="line">            a_href_text = requests.get(url=a_href, headers=headers).text.encode(<span class="string">&#x27;ISO-8859-1&#x27;</span>)</span><br><span class="line">            a_tree = etree.HTML(a_href_text)</span><br><span class="line">            a_src = a_tree.xpath(<span class="string">&#x27;//div[@class=&quot;down_wrap&quot;]/div[2]/ul/li[3]/a/@href&#x27;</span>)[<span class="number">0</span>]</span><br><span class="line">            <span class="comment"># 此处增加去除开头和结尾的空格</span></span><br><span class="line">            a_name = a_tree.xpath(<span class="string">&#x27;//div[@class=&quot;bgwhite&quot;]/div/h1/text()&#x27;</span>)[<span class="number">0</span>].strip() + <span class="string">&#x27;.rar&#x27;</span></span><br><span class="line">            <span class="comment"># 该方式于此处似乎无效</span></span><br><span class="line">            <span class="comment"># 试下.content.decode(&#x27;utf-8&#x27;)</span></span><br><span class="line">            <span class="comment"># a_name = a_name.encode(&#x27;ISO-8859-1&#x27;).decode(&#x27;gbk&#x27;)</span></span><br><span class="line">            <span class="comment"># print(a_name)</span></span><br><span class="line">            <span class="comment"># print(a_src)</span></span><br><span class="line">            <span class="comment"># 获取二进制数据，写入a_name文件</span></span><br><span class="line">            rar_page = requests.get(url=a_src, headers=headers).content</span><br><span class="line">            <span class="keyword">with</span> <span class="built_in">open</span>(<span class="string">&#x27;./jianli/&#x27;</span> + a_name, <span class="string">&#x27;wb&#x27;</span>) <span class="keyword">as</span> fp:</span><br><span class="line">                fp.write(rar_page)</span><br><span class="line">                fp.close()</span><br><span class="line">                <span class="built_in">print</span>(a_name + <span class="string">&#x27;--&gt;下载完毕！！！&#x27;</span>)</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;\n当前拉取到第&#123;&#125;页&quot;</span>.<span class="built_in">format</span>(x))</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;\n全部简历拉取结束！！！&#x27;</span>)</span><br></pre></td></tr></table></figure></div><div class="post-copyright-info"><div class="article-copyright-info-container"><ul class="copyright-info-content"><li><span class="type">本文标题</span>：<span class="content">爬虫之数据解析相关</span></li><li><span class="type">本文作者</span>：<span class="content">涂寐</span></li><li><span class="type">创建时间</span>：<span class="content">2021-12-28 10:26:20</span></li><li class="post-link"><span class="type">本文链接</span>：<span class="content">article/c86c0afc.html</span></li><li><span class="type">版权声明</span>：<span class="content">本博客所有文章除特别声明外，均采用 <a class="license" target="_blank" rel="noopener" href="https://creativecommons.org/licenses/by-nc-sa/4.0/deed.zh">BY-NC-SA</a> 许可协议。转载请注明出处！</span></li></ul></div></div><ul class="post-tags-box"><li class="tag-item"><a href="/tags/crawler/">#爬虫</a>&nbsp;</li></ul><div class="article-nav"><div class="article-prev"><a class="prev" rel="prev" href="/article/74cf08f5.html"><span class="left arrow-icon flex-center"><i class="fas fa-chevron-left"></i> </span><span class="title flex-center"><span class="post-nav-title-item">爬虫之验证码相关</span> <span class="post-nav-item">上一篇</span></span></a></div><div class="article-next"><a class="next" rel="next" href="/article/82b683e3.html"><span class="title flex-center"><span class="post-nav-title-item">爬虫之requests模块相关</span> <span class="post-nav-item">下一篇</span> </span><span class="right arrow-icon flex-center"><i class="fas fa-chevron-right"></i></span></a></div></div><div class="comment-container"><div class="comments-container"><div id="comments-anchor"></div><div class="comment-area-title"><i class="fas fa-comments"></i>&nbsp;评论</div><div class="valine-container"><script data-pjax src="//cdn.jsdelivr.net/npm/valine@latest/dist/Valine.min.js"></script><div id="vcomments"></div><script data-pjax>function loadValine(){function e(e){switch(e){case"en":return"Author";case"zh-CN":return"博主";default:return"Master"}}new Valine({el:"#vcomments",appId:"FrcGiaBdfMQqXAnDFY1gwHbS-gzGzoHsz",appKey:"C0Wy6Sfq0qVag0nm59fc1D12",meta:["nick","mail","link"],avatar:"wavatar",enableQQ:!0,placeholder:"道友，请留步！请留言~",lang:"zh-CN".toLowerCase()});const a=setInterval(()=>{const n=document.querySelectorAll("#vcomments .vcards .vcard");if(n.length>0){let t="涂寐";if(t)for(let a of n){const n=a.querySelector(".vhead .vnick"),l=n.innerHTML;l===t&&(n.innerHTML=`${l} <span class="author">${e(KEEP.hexo_config.language)}</span>`)}clearInterval(a)}else clearInterval(a)},2e3)}{const e=setTimeout(()=>{loadValine(),clearTimeout(e)},1e3)}</script></div></div></div></div><div class="toc-content-container"><div class="post-toc-wrap"><div class="post-toc"><ol class="nav"><li class="nav-item nav-level-2"><a class="nav-link" href="#%E5%A3%B0%E6%98%8E"><span class="nav-number">1.</span> <span class="nav-text">声明</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E8%81%9A%E7%84%A6%E7%88%AC%E8%99%AB"><span class="nav-number">2.</span> <span class="nav-text">聚焦爬虫</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E7%BC%96%E7%A0%81%E6%B5%81%E7%A8%8B"><span class="nav-number">3.</span> <span class="nav-text">编码流程</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E6%96%B9%E6%B3%95%E5%88%86%E7%B1%BB"><span class="nav-number">4.</span> <span class="nav-text">方法分类</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E7%AE%80%E8%BF%B0%E4%BD%BF%E7%94%A8"><span class="nav-number">5.</span> <span class="nav-text">简述使用</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E6%AD%A3%E5%88%99%E8%A1%A8%E8%BE%BE%E5%BC%8F"><span class="nav-number">6.</span> <span class="nav-text">正则表达式</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E7%BD%91%E9%A1%B5%E6%BA%90%E4%BB%A3%E7%A0%81"><span class="nav-number">6.1.</span> <span class="nav-text">网页源代码</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%8F%96src%E6%AD%A3%E5%88%99"><span class="nav-number">6.2.</span> <span class="nav-text">取src正则</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E7%B3%97%E4%BA%8B%E7%99%BE%E7%A7%91%E7%B3%97%E5%9B%BE"><span class="nav-number">6.3.</span> <span class="nav-text">糗事百科糗图</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#BS4%E8%A7%A3%E6%9E%90"><span class="nav-number">7.</span> <span class="nav-text">BS4解析</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E7%AE%80%E8%BF%B0%E5%8E%9F%E7%90%86"><span class="nav-number">7.1.</span> <span class="nav-text">简述原理</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E7%8E%AF%E5%A2%83%E5%AE%89%E8%A3%85"><span class="nav-number">7.2.</span> <span class="nav-text">环境安装</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E4%BD%BF%E7%94%A8%E6%A6%82%E8%A6%81"><span class="nav-number">7.3.</span> <span class="nav-text">使用概要</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E7%9B%B8%E5%85%B3%E5%B1%9E%E6%80%A7%E5%92%8C%E6%96%B9%E6%B3%95"><span class="nav-number">7.4.</span> <span class="nav-text">相关属性和方法</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E6%9C%AC%E5%9C%B0%E6%B5%8B%E8%AF%95"><span class="nav-number">7.5.</span> <span class="nav-text">本地测试</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E4%B8%89%E5%9B%BD%E6%BC%94%E4%B9%89%E5%B0%8F%E8%AF%B4"><span class="nav-number">7.6.</span> <span class="nav-text">三国演义小说</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#xpath%E8%A7%A3%E6%9E%90"><span class="nav-number">8.</span> <span class="nav-text">xpath解析</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%8E%9F%E7%90%86"><span class="nav-number">8.1.</span> <span class="nav-text">原理</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E7%8E%AF%E5%A2%83"><span class="nav-number">8.2.</span> <span class="nav-text">环境</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E4%BD%BF%E7%94%A8%E4%B8%BE%E4%BE%8B"><span class="nav-number">8.3.</span> <span class="nav-text">使用举例</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#xpath%E8%A1%A8%E8%BE%BE%E5%BC%8F"><span class="nav-number">8.4.</span> <span class="nav-text">xpath表达式</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E6%9C%AC%E5%9C%B0%E6%B5%8B%E8%AF%95-1"><span class="nav-number">8.5.</span> <span class="nav-text">本地测试</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#58%E4%BA%8C%E6%89%8B%E6%88%BF"><span class="nav-number">8.6.</span> <span class="nav-text">58二手房</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%BD%BC%E5%B2%B8%E5%9B%BE%E7%BD%91%E5%9B%BE%E7%89%87"><span class="nav-number">8.7.</span> <span class="nav-text">彼岸图网图片</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E7%A9%BA%E6%B0%94%E6%A3%80%E6%B5%8B%E5%B9%B3%E5%8F%B0%E5%9F%8E%E5%B8%82"><span class="nav-number">8.8.</span> <span class="nav-text">空气检测平台城市</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E7%AB%99%E9%95%BF%E4%B9%8B%E5%AE%B6%E5%85%8D%E8%B4%B9%E7%AE%80%E5%8E%86"><span class="nav-number">8.9.</span> <span class="nav-text">站长之家免费简历</span></a></li></ol></li></ol></div></div></div></div></div></div></div><div class="page-main-content-bottom"><footer class="footer"><div class="info-container"><div class="copyright-info info-item">&copy; <span>2021</span> - 2023 &nbsp;<i class="fas fa-heart icon-animate" style="color:red"></i> &nbsp;<a href="/">涂寐</a></div><script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script><div class="website-count info-item"></div><div class="theme-info info-item">由 <a target="_blank" href="https://hexo.io">Hexo</a> 驱动&nbsp;|&nbsp;主题&nbsp;<a class="theme-version" target="_blank" href="https://github.com/XPoet/hexo-theme-keep">Keep v3.5.2</a></div><script id="LA-DATA-WIDGET" crossorigin="anonymous" charset="UTF-8" src="https://v6-widget.51.la/v6/JiZItHVhLKBShkL0/quote.js?theme=#1690FF,#333333,#999999,#333333,#FFFFFF,#1690FF,18&f=18&display=0,0,1,1,0,1,1,1"></script></div></footer></div></div><div class="post-tools"><div class="post-tools-container"><ul class="tools-list"><li class="tools-item flex-center toggle-show-toc"><i class="fas fa-list"></i></li><li class="tools-item flex-center go-to-comments"><i class="fas fa-comment"></i> <span class="post-comments-count"></span></li></ul></div></div><div class="right-bottom-side-tools"><div class="side-tools-container"><ul class="side-tools-list"><li class="tools-item tool-font-adjust-plus flex-center"><i class="fas fa-search-plus"></i></li><li class="tools-item tool-font-adjust-minus flex-center"><i class="fas fa-search-minus"></i></li><li class="tools-item tool-dark-light-toggle flex-center"><i class="fas fa-moon"></i></li><li class="tools-item tool-scroll-to-bottom flex-center"><i class="fas fa-arrow-down"></i></li></ul><ul class="exposed-tools-list"><li class="tools-item tool-toggle-show flex-center"><i class="fas fa-cog fa-spin"></i></li><li class="tools-item tool-scroll-to-top flex-center"><i class="arrow-up fas fa-arrow-up"></i> <span class="percent"></span></li></ul></div></div><div class="zoom-in-image-mask"><img class="zoom-in-image"></div><div class="search-pop-overlay"><div class="popup search-popup"><div class="search-header"><span class="search-input-field-pre"><i class="fas fa-keyboard"></i></span><div class="search-input-container"><input autocomplete="off" autocorrect="off" autocapitalize="off" placeholder="搜索..." spellcheck="false" type="search" class="search-input"></div><span class="close-popup-btn"><i class="fas fa-times"></i></span></div><div id="search-result"><div id="no-result"><i class="fas fa-spinner fa-pulse fa-5x fa-fw"></i></div></div></div></div></main><script src="//cdn.jsdelivr.net/npm/hexo-theme-keep@3.5.2/source/js/utils.js"></script><script src="//cdn.jsdelivr.net/npm/hexo-theme-keep@3.5.2/source/js/main.js"></script><script src="//cdn.jsdelivr.net/npm/hexo-theme-keep@3.5.2/source/js/header-shrink.js"></script><script src="//cdn.jsdelivr.net/npm/hexo-theme-keep@3.5.2/source/js/back2top.js"></script><script src="//cdn.jsdelivr.net/npm/hexo-theme-keep@3.5.2/source/js/dark-light-toggle.js"></script><script src="//cdn.jsdelivr.net/npm/hexo-theme-keep@3.5.2/source/js/local-search.js"></script><script src="//cdn.jsdelivr.net/npm/hexo-theme-keep@3.5.2/source/js/code-block.js"></script><script src="//cdn.jsdelivr.net/npm/hexo-theme-keep@3.5.2/source/js/lazyload.js"></script><div class="post-scripts pjax"><script src="//cdn.jsdelivr.net/npm/hexo-theme-keep@3.5.2/source/js/post-helper.js"></script><script src="//cdn.jsdelivr.net/npm/hexo-theme-keep@3.5.2/source/js/libs/anime.min.js"></script><script src="//cdn.jsdelivr.net/npm/hexo-theme-keep@3.5.2/source/js/toc.js"></script></div><script src="//cdn.jsdelivr.net/npm/hexo-theme-keep@3.5.2/source/js/libs/pjax.min.js"></script><script>window.addEventListener("DOMContentLoaded",()=>{window.pjax=new Pjax({selectors:["head title",".page-container",".pjax"],history:!0,debug:!1,cacheBust:!1,timeout:0,analytics:!1,currentUrlFullReload:!1,scrollRestoration:!1}),document.addEventListener("pjax:send",()=>{KEEP.utils.pjaxProgressBarStart()}),document.addEventListener("pjax:complete",()=>{KEEP.utils.pjaxProgressBarEnd(),window.pjax.executeScripts(document.querySelectorAll("script[data-pjax], .pjax script")),KEEP.refresh()})})</script></body></html>